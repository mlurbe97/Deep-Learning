{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.2554 - acc: 0.9262\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.1036 - acc: 0.9694\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 0.0694 - acc: 0.9788\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0499 - acc: 0.9853\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0374 - acc: 0.9885\n",
      "10000/10000 [==============================] - 0s 30us/step\n",
      "test_acc: 0.9802\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "print(keras.__version__)\n",
    "\n",
    "from keras.datasets import mnist\n",
    "#Cargamos los datos de entrenamiento y de test\n",
    "(train_images, train_labels) ,(test_images,test_labels) = mnist.load_data()\n",
    "\n",
    "#Las imagenes de entrada se almacenan en tensores Numpy, que son\n",
    "#formateados como tensores float32 de forma (60000, 784) (datos de entrenamiento)\n",
    "#y (10000,784) (datos de prueba)\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n",
    "#Dimension del tensor en cada eje (axis), # Total no. de imagenes de entrenamiento\n",
    "train_images.shape\n",
    "#train_labels\n",
    "\n",
    "#Dimension del tensor en cada eje (axis), # Total no. de imagenes de test\n",
    "test_images.shape\n",
    "#test_labels\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import sgd\n",
    "\n",
    "#Esta es nuestra red\n",
    "network = Sequential()\n",
    "\n",
    "#Esta red consiste en una cadena de dos capas densas, que\n",
    "#Cada capa aplica unas pocas operaciones de tensor simple a los datos de entrada,\n",
    "#y que estas operaciones involucran tensores de peso. Tensores de peso, que son atributos\n",
    "#de las capas, es donde persiste el conocimiento de la red.\n",
    "network.add(Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
    "network.add(Dense(10, activation='softmax'))\n",
    "\n",
    "#categorical_crossentropy es la función de pérdida que se usa\n",
    "#como una señal de retroalimentación para aprender los tensores de peso,\n",
    "#y la fase de entrenamiento intenta de minimizar. \n",
    "#Esta reducción de la pérdida ocurre a través de stochastic gradient descent.\n",
    "#Las reglas exactas que gobiernan un uso específico del gradiente de descenso\n",
    "#se definen mediante el optimizador rmsprop pasado como primer argumento.\n",
    "network.compile(optimizer='rmsprop',\n",
    "loss='categorical_crossentropy',\n",
    "metrics=['accuracy'])\n",
    "\n",
    "#Conversion de los datos\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "\n",
    "#Ahora entiendes lo que sucede cuando consideras que es correcto: la red comenzará a iterar\n",
    "#en los datos de entrenamiento en mini-lotes de 128 muestras, 5 veces más (cada iteración sobre\n",
    "#Todos los datos de entrenamiento se llaman época. En cada iteración, la red computará la\n",
    "#gradientes de los pesos con respecto a la pérdida en el lote, y actualice los pesos en consecuencia. Después de estas 5 épocas, la red habrá realizado 2,345 gradientes.\n",
    "#actualizaciones (469 por época), y la pérdida de la red será lo suficientemente baja como para que la\n",
    "#La red será capaz de clasificar los dígitos escritos a mano con alta precisión.\n",
    "network.fit(train_images, train_labels, epochs=5, batch_size=128)\n",
    "\n",
    "#test de los datos\n",
    "test_loss, test_acc = network.evaluate(test_images, test_labels)\n",
    "print('test_acc:', test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
