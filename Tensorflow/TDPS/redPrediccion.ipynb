{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "Using TensorFlow backend.\n"
    },
    {
     "data": {
      "text/plain": "'2.2.4-tf'"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Counters:\n\n[[1.31943900e+00 1.29050400e+00 1.30348400e+00 ... 6.58438130e+07\n  1.70366900e+06 2.04187930e+07]\n [1.29835700e+00 1.27056200e+00 1.29895900e+00 ... 6.43080120e+07\n  4.33270700e+06 1.93726630e+07]\n [1.28217200e+00 1.29810500e+00 1.28717600e+00 ... 7.15462400e+07\n  5.29492800e+06 1.93492280e+07]\n ...\n [1.00086100e+00 1.00314100e+00 1.00086100e+00 ... 4.48407155e+08\n  1.98159000e+06 8.73024000e+05]\n [1.00087000e+00 1.00318500e+00 1.00086900e+00 ... 4.48996860e+08\n  1.72234800e+06 8.71582000e+05]\n [1.00088000e+00 1.00676100e+00 1.00087800e+00 ... 4.48782413e+08\n  1.67138200e+06 8.62587000e+05]]\n\nDSCR values:\n\n[ 0.  0.  0. ... 71. 71. 71.]\n\nIPC labels:\n\n[1.298357 1.282172 1.28414  ... 1.00087  1.00088  1.000897]\n"
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataframe = pd.read_csv(\"dataset.csv\", header=0)\n",
    "dataset = dataframe.values\n",
    "\n",
    "X1 = dataset[:,1] # Get the DSCR as RAW value.\n",
    "Y = dataset[:,0].astype(float) # Get IPC label for training as Float.\n",
    "X2 = dataset[0:,2:].astype(float) # Get 4 last IPC and 16 counter values as Float.\n",
    "\n",
    "print(\"Counters:\\n\")\n",
    "print(X2)\n",
    "print(\"\\nDSCR values:\\n\")\n",
    "print(X1)\n",
    "print(\"\\nIPC labels:\\n\")\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Labels: 23040\nInputs: 23040\nX_Train: 16128\nY_Train: 16128\nX_Test: 6912\nY_Test: 6912\nShape = 24\n"
    }
   ],
   "source": [
    "# Encode class DSCR as integer values\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(X1)\n",
    "encoded_X1 = encoder.transform(X1)\n",
    "\n",
    "# Convert integers to dummy variables (one hot encoded).\n",
    "dummy_x = np_utils.to_categorical(encoded_X1).astype(float)\n",
    "\n",
    "# Convert to dataframe to merge columns\n",
    "dataframe_X1 = pd.DataFrame(dummy_x);\n",
    "dataframe_X2 = pd.DataFrame(X2);\n",
    "\n",
    "dataframe_X = pd.DataFrame.merge(dataframe_X1, dataframe_X2,left_index=True, right_index=True) # Merge model inputs\n",
    "\n",
    "# Converting back to <class 'numpy.ndarray'>\n",
    "X = dataframe_X.values;\n",
    "\n",
    "# Labels and inputs, must be the same size\n",
    "print(\"Labels: \"+str(len(Y))) # Model label training input\n",
    "print(\"Inputs: \"+str(len(X))) # Model inputs\n",
    "\n",
    "# Fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Taining and test split-> 30% test - 70% training\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.30, random_state=seed)\n",
    "\n",
    "# Train and test data, must be the same size\n",
    "print(\"X_Train: \"+str(len(X_train)))\n",
    "print(\"Y_Train: \"+str(len(Y_train)))\n",
    "print(\"X_Test: \"+str(len(X_test)))\n",
    "print(\"Y_Test: \"+str(len(Y_test)))\n",
    "\n",
    "# Shape of the input, number of model features\n",
    "in_shape = X_train.shape[1]\n",
    "print(\"Shape = \"+str(in_shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Number of inputs for the model: 24\n"
    }
   ],
   "source": [
    "print(\"Number of inputs for the model: \"+str(in_shape))\n",
    "\n",
    "# https://keras.io/optimizers/\n",
    "optimizers = ['sgd','rmsprop','adagrad','adadelta','adam','adamax','nadam'];\n",
    "\n",
    "# https://keras.io/metrics/\n",
    "metrics = ['mean_absolute_error','cosine_proximity','sparse_top_k_categorical_accuracy','top_k_categorical_accuracy','sparse_categorical_accuracy','categorical_accuracy','binary_accuracy','accuracy'];\n",
    "\n",
    "# https://keras.io/losses/\n",
    "losses = ['mean_squared_error','mean_absolute_error','mean_absolute_percentage_error','mean_squared_logarithmic_error','squared_hinge','hinge','categorical_hinge','logcosh','huber_loss','categorical_crossentropy','sparse_categorical_crossentropy','binary_crossentropy','kullback_leibler_divergence','poisson','cosine_proximity','is_categorical_crossentropy'];\n",
    "\n",
    "# https://keras.io/activations/\n",
    "activations = ['relu','softmax','tanh','elu','selu','softplus','softsign','sigmoid','hard_sigmoid','exponential','linear'];\n",
    "\n",
    "# Model definition as function\n",
    "def PC_IBM_model():\n",
    "\t# Create model\n",
    "\tmodel = Sequential()\n",
    "\t\n",
    "\t# Deepnet layers definition\n",
    "\tmodel.add(Dense(10, input_shape=(in_shape,), activation='sigmoid'))\n",
    "\tmodel.add(Dense(32, activation='sigmoid'))\n",
    "\tmodel.add(Dense(1))\n",
    "\t\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='mean_squared_error', optimizer='sgd', metrics=['mean_absolute_error'])\n",
    "\n",
    "\t# Show model definition\n",
    "\tmodel.summary();\n",
    "\t\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "an_absolute_error: 0.2441\nEpoch 1037/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1090 - mean_absolute_error: 0.2442\nEpoch 1038/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1090 - mean_absolute_error: 0.2436\nEpoch 1039/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1090 - mean_absolute_error: 0.2434\nEpoch 1040/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1090 - mean_absolute_error: 0.2437\nEpoch 1041/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1090 - mean_absolute_error: 0.2437\nEpoch 1042/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1090 - mean_absolute_error: 0.2430\nEpoch 1043/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1090 - mean_absolute_error: 0.2434\nEpoch 1044/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1090 - mean_absolute_error: 0.2439\nEpoch 1045/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1090 - mean_absolute_error: 0.2438\nEpoch 1046/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1090 - mean_absolute_error: 0.2437\nEpoch 1047/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1090 - mean_absolute_error: 0.2431\nEpoch 1048/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1090 - mean_absolute_error: 0.2436\nEpoch 1049/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1090 - mean_absolute_error: 0.2436\nEpoch 1050/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1090 - mean_absolute_error: 0.2437\nEpoch 1051/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1090 - mean_absolute_error: 0.2428\nEpoch 1052/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1090 - mean_absolute_error: 0.2439\nEpoch 1053/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1090 - mean_absolute_error: 0.2438\nEpoch 1054/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1090 - mean_absolute_error: 0.2439\nEpoch 1055/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1090 - mean_absolute_error: 0.2436\nEpoch 1056/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1090 - mean_absolute_error: 0.2438\nEpoch 1057/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1090 - mean_absolute_error: 0.2434\nEpoch 1058/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1090 - mean_absolute_error: 0.2441\nEpoch 1059/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1090 - mean_absolute_error: 0.2442\nEpoch 1060/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1090 - mean_absolute_error: 0.2436\nEpoch 1061/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1090 - mean_absolute_error: 0.2446\nEpoch 1062/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1090 - mean_absolute_error: 0.2436\nEpoch 1063/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1090 - mean_absolute_error: 0.2431\nEpoch 1064/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1090 - mean_absolute_error: 0.2434\nEpoch 1065/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1090 - mean_absolute_error: 0.2434\nEpoch 1066/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1090 - mean_absolute_error: 0.2427\nEpoch 1067/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1090 - mean_absolute_error: 0.2434\nEpoch 1068/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1090 - mean_absolute_error: 0.2433\nEpoch 1069/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1090 - mean_absolute_error: 0.2429\nEpoch 1070/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1090 - mean_absolute_error: 0.2431\nEpoch 1071/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1090 - mean_absolute_error: 0.2441\nEpoch 1072/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1090 - mean_absolute_error: 0.2439\nEpoch 1073/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1090 - mean_absolute_error: 0.2439\nEpoch 1074/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1090 - mean_absolute_error: 0.2436\nEpoch 1075/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2435\nEpoch 1076/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1090 - mean_absolute_error: 0.2438\nEpoch 1077/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1090 - mean_absolute_error: 0.2445\nEpoch 1078/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2434\nEpoch 1079/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2441\nEpoch 1080/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1090 - mean_absolute_error: 0.2429\nEpoch 1081/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1090 - mean_absolute_error: 0.2429\nEpoch 1082/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2434\nEpoch 1083/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2438\nEpoch 1084/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2439\nEpoch 1085/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2438\nEpoch 1086/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2434\nEpoch 1087/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2434\nEpoch 1088/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2433\nEpoch 1089/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2439\nEpoch 1090/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2433\nEpoch 1091/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2434\nEpoch 1092/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2443\nEpoch 1093/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2437\nEpoch 1094/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1090 - mean_absolute_error: 0.2432\nEpoch 1095/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2430\nEpoch 1096/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2434\nEpoch 1097/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2438\nEpoch 1098/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2433\nEpoch 1099/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1090 - mean_absolute_error: 0.2450\nEpoch 1100/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2439\nEpoch 1101/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2437\nEpoch 1102/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2437\nEpoch 1103/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1090 - mean_absolute_error: 0.2440\nEpoch 1104/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2442\nEpoch 1105/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1090 - mean_absolute_error: 0.2429\nEpoch 1106/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1090 - mean_absolute_error: 0.2425\nEpoch 1107/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2436\nEpoch 1108/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2435\nEpoch 1109/1200\n 2000/16128 [==>...........................] - ETA: 0s - loss: 0.1077 - mean_absolute_error: 0.24316128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2437\nEpoch 1110/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2437\nEpoch 1111/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2440\nEpoch 1112/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2433\nEpoch 1113/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2437\nEpoch 1114/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2441\nEpoch 1115/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2441\nEpoch 1116/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2438\nEpoch 1117/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1090 - mean_absolute_error: 0.2430\nEpoch 1118/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2443\nEpoch 1119/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2439\nEpoch 1120/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2436\nEpoch 1121/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2438\nEpoch 1122/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2440\nEpoch 1123/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2438\nEpoch 1124/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2434\nEpoch 1125/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1090 - mean_absolute_error: 0.2446\nEpoch 1126/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2443\nEpoch 1127/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2441\nEpoch 1128/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2435\nEpoch 1129/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2437\nEpoch 1130/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2431\nEpoch 1131/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2439\nEpoch 1132/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2436\nEpoch 1133/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2436\nEpoch 1134/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2435\nEpoch 1135/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2435\nEpoch 1136/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2435\nEpoch 1137/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2432\nEpoch 1138/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2441\nEpoch 1139/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2430\nEpoch 1140/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1090 - mean_absolute_error: 0.2448\nEpoch 1141/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2441\nEpoch 1142/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1090 - mean_absolute_error: 0.2448\nEpoch 1143/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2437\nEpoch 1144/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1090 - mean_absolute_error: 0.2447\nEpoch 1145/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2435\nEpoch 1146/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2440\nEpoch 1147/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2436\nEpoch 1148/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2435\nEpoch 1149/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2436\nEpoch 1150/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2441\nEpoch 1151/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2436\nEpoch 1152/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2438\nEpoch 1153/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1090 - mean_absolute_error: 0.2428\nEpoch 1154/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2432\nEpoch 1155/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2440\nEpoch 1156/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2439\nEpoch 1157/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2430\nEpoch 1158/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2434\nEpoch 1159/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2436\nEpoch 1160/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2433\nEpoch 1161/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2430\nEpoch 1162/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2432\nEpoch 1163/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2439\nEpoch 1164/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2440\nEpoch 1165/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2435\nEpoch 1166/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2435\nEpoch 1167/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2430\nEpoch 1168/1200\n 2000/16128 [==>...........................] - ETA: 0s - loss: 0.1149 - mean_absolute_error: 0.24516128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2430\nEpoch 1169/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2435\nEpoch 1170/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2438\nEpoch 1171/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2436\nEpoch 1172/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2434\nEpoch 1173/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2443\nEpoch 1174/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2430\nEpoch 1175/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2437\nEpoch 1176/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2436\nEpoch 1177/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2433\nEpoch 1178/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2442\nEpoch 1179/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2434\nEpoch 1180/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2437\nEpoch 1181/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2429\nEpoch 1182/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2434\nEpoch 1183/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2436\nEpoch 1184/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2439\nEpoch 1185/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2430\nEpoch 1186/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2440\nEpoch 1187/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2429\nEpoch 1188/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2436\nEpoch 1189/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2432\nEpoch 1190/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2440\nEpoch 1191/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2441\nEpoch 1192/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2439\nEpoch 1193/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2431\nEpoch 1194/1200\n 2000/16128 [==>...........................] - ETA: 0s - loss: 0.1033 - mean_absolute_error: 0.23716128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2434\nEpoch 1195/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2429\nEpoch 1196/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2429\nEpoch 1197/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2433\nEpoch 1198/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2436\nEpoch 1199/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2436\nEpoch 1200/1200\n16128/16128 [==============================] - 0s 1us/step - loss: 0.1089 - mean_absolute_error: 0.2438\n"
    }
   ],
   "source": [
    "# batch_size -> Divide dataset in batches of 100.\n",
    "# epochs -> Number of times that we are applying the process to each 100 examples of data.\n",
    "num_epochs = 1200;\n",
    "num_batch = 2000;\n",
    "model = PC_IBM_model();\n",
    "\n",
    "#estimator = KerasClassifier(build=PC_IBM_model, epochs=5, batch_size=100)\n",
    "model.fit(X_train, Y_train, epochs=num_epochs, batch_size=num_batch);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "6912/6912 [==============================] - 0s 9us/step\nTest metric: 24.79%\nTest loss: 11.39%\n"
    }
   ],
   "source": [
    "test_loss, test_metric = model.evaluate(X_test, Y_test)\n",
    "print('Test metric: %.2f%%' % (test_metric*100))\n",
    "print('Test loss: %.2f%%' % (test_loss*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Saved model to disk\n"
    }
   ],
   "source": [
    "# Save model and architecture to single file\n",
    "model.save(\"PC_IBM_model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "# load model\n",
    "model = load_model('PC_IBM_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}